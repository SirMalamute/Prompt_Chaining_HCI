# Experiments to Quantify AI Implicit Bias/Assumptions When Analyzing Sexism (LLM HCI).

# Guiding question: Can AI be less biased after refinement? <br>

# Methodology <br>
- Created a dataset of 70 scenarios to force LLM's to make a choice using GPT3.5 <br>
- Used two approaches to collect further data <br>
  - Assumption Questioning <br>
  - Bias Questioning <br>

# Assumption Questioning <br>
- Asks LLMs what assumptions are made when answering a question <br>
- Questions a LLM to investigate if those assumptions are factual <br>
- Returns a renewed answer <br>

# Bias Questioning <br>
- Asks a LLM whether the initial answer was biased <br>
- Asks a LLM to rewrite the answer based on the answer to the previous question <br>


# Future Work <br>
- Dataset tagging <br>
- Original analysis bias detection (implicit bias?) 
